{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Dominik Wiśniewski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to solve the problem, I first reviewed the LR literature, then summarized and presented the above issue. Then I made a preliminary analysis of the data set and then tried the methods described above on it. At the end I presented a solution to the problem but without its implementation because of the time consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Literature review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, articles related to Learning to Rate will be described in order to present the topic of the topic and review available solutions, as well as assess their usefulness in completing the recruitment task. Not all articles will be described here, due to the relatively short time to complete the task and the amount of work to be described. There will be more interesting ones from among those to which I had free access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. A Short Introduction to Learning to Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi Lang in his article \"A Short Introduction to Learning to Rate\" explains fundamental problems, existing approaches and future work of learning to rank of which he described in detail the methods based on SVM, and in order not to lose generality, the article discusses documents retrival.\n",
    "The first chapter focuses on the problems of Learning to rate. At first author described the documents retrival problem and presents its solution in a traditional ranking model using probability distributions that can be calculated by tuning several parameters. The next step was the transition to the description of ranking models using machine learning and the challenges that came with it: training and testing, data labeling, feature construction, evaluation metrics and relations with ordinal classification.\n",
    "The second chapter was devoted to writing the Learning to rate approach in a formal mathematical language. Functions that are used, optimized values or how to calculate individual metrics.\n",
    "Chapters three, four and five present the approaches pointwise approach, pairwise approach and listwise approach. Each of the approaches is generally described and presented in detail on methods using selected SVM-based methods.\n",
    "Finally, the author presents open problems based on Learning to rate. The whole is a general introduction for those not familiar with the topic with examples describing a specific issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Learning to Rank for Information Retrieval Using Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper discusses work on using machine learning to automatically produce an effective ranking function for information retrival. A learning method, RankGP, based on genetic programming is developed to learn a ranking function by combining different types of evidences in IR, including content features, structure features, and query-independent features. RankGP represents a potential solution (i.e., a ranking function) as an individual in a population of genetic prgramming. The method evolves a population by applying genetic operations, such as crossover and mutation, over a series of generations. In each generation, a fitness function, modeled as an IR measure, MAP (Mean Average Precision), is exploited to evaluate the performance of each individual in the population. The evolution is supposed to eventually generate an individual with the best fitness as the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Self-organizing Semantic Map for Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network’s unsupervised learning algorithm, Kohonen’s feature map, is applied to constructing a selforganizing semantic map for information retrieval. The semantic map visualizes semantic relationships between input documents, and has properties of economic representation of data with their interrelationships. The potentials of the semantic map include using the map as a retrieval interface for an online bibliographic system. A prototype system that demonstrates this potential is described in this article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors' contribution consists of two parts: \n",
    "First, they propose a multi-task deep neural network for representation learning, in particular focusing on semantic classification (query classification) and semantic information retrieval (ranking for web search) tasks. They model learns to map arbitrary text queries and documents into semantic vector representations in a low dimensional latent space. While the general concept of multi-task neural nets is not new, they model is novel in that it successfully combines tasks as disparate as operations necessary for classification or ranking. \n",
    "Second, they demonstrate strong results on query classification and web search. They multi-task representation learning consistently outperforms stateof-the-art baselines. Meanwhile, they show that their model is not only compact but it also enables agile deployment into new domains. This is because the learned representations allow domain adaptation with substantially fewer in-domain labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Using Genetic Algorithm to Improve Information Retrieval Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper authors introduce a new fitness function and compare its results with GA based on Cosine fitness function and Classical IR in query learning problems. Their fitness function has been applied on three well-known test collections, to gain an exhaustive view of improvement information retrieval systems using genetic techniques. The article accurately describes the method used and is worth reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Learning to Rank by Optimizing NDCG Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors propose a probabilistic framework that addresses this challenge by optimizing the expectation of NDCG over all the possible permutations of documents. A relaxation strategy is used to approximate the average of NDCG over the space of permutation, and a bound optimization approach is proposed to make the computation efficient. Extensive experiments show that the proposed algorithm outperforms state-of-the-art ranking algorithms on several benchmark data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Listwise Approach to Learning to Rank - Theory and Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper aims to conduct a study on the listwise approach to learning to rank. The listwise approach learns a ranking function by taking individual lists as instances and minimizing a loss function defined on the predicted list and the ground-truth list. Existing work on the approach mainly focused on the development of new algorithms; methods such as RankCosine and ListNet have been proposed and good performances by them have been observed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Reinforcement Learning to Rank in E-Commerce Search Engine: Formalization, Analysis, and Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper, we focus on the problem of ranking items in largescale item search engines, which refers to assigning each item a score and sorting the items according to their scores. Generally, a search session between a user and the search engine is a multi-step ranking problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning to rate concept will be approximated at this point. The three main approaches to solving learning to rate problems will be briefly described, as well as two popular metrics in learning to rate based solutions, one of which is to be included in the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning to rank can be employed in a wide variety of applications in Information Retrieval (IR), Natural Language Processing (NLP), and Data Mining (DM). Typical applications are document retrieval, expert search, definition search, collaborative filtering, question answering, keyphrase extraction, document summarization, and machine translation.\n",
    "The system maintains a collection of documents. Given a query, the system retrieves documents containing the query words from the collection, ranks the documents, and returns the top ranked documents. The ranking task is performed by using a ranking model f(q, d) to sort the documents, where q denotes a query and d denotes a document. The training corpus is created as a set of query-document pairs upon which a relevance judgment indicating the relationship between qi and dj is assigned by a labeler. The relevance judgment can be:\n",
    "+ a class label, e.g., relevant or non-relevant \n",
    "+ a rating, e.g., definitely relevant, possibly relevant, or non-relevant\n",
    "+ an order, e.g., k, meaning that dj is ranked in the k-th position of the ordering of all documents when qi is considered \n",
    "+ a score, e.g., sim(qi, dj), specifying the degree of relevance between qi and dj. For each instance, (qi, dj), a feature extractor produces a vector of features that describe the match between qi and dj.\n",
    "\n",
    "The inputs to the learning algorithm comprise training instances, their feature vectors, and the corresponding relevance judgments. The output is a ranking function, f, where f(qi, dj) is supposed to give the “true” relevance judgment (as mentioned previously) for qi and dj. During the training process, the learning algorithm attempts to learn a ranking function such that a performance measure (e.g., classification accuracy, error rate, Mean Average Precision, etc.) with respect to the output relevance judgments can be optimized. In the test phase, the learned ranking function is applied to determine the relevance between each document di in D and a new query q. Clearly, factors, such as the form of the training instances, the form of the desired output, and the performance measure, will lead to different design of learning to rank for IR algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pointwise Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input space of the pointwise approach contains a feature vector of each single document.\n",
    "The output space contains the relevance degree of each single document.\n",
    "The hypothesis space contains function that take the feature vector of a document as input and predict the relevance degree of the document. Researchers usually call such a function the scoring function. Based on the scoring function, one can sort all the documents and produce the final ranked list.\n",
    "The loss function examines the accurate prediction of the ground truth label for each single document. In different pointwise ranking algorithms, ranking is modeled as regression, classification, and ordinal regression. Therefore the corresponding regression loss, classification loss and ordinary regression loss are used as the loss function.\n",
    "Pointwise approach does not consider the inter-dependency between documents, and thus the position of a document in the final ranked list is invisible to its loss function. The approach does not make use of the fact that some documents are actually associated with the same query. It is worth to consider that most evaluation measures for information retrieval are query level and position based, the pointwise approach has its limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pairtwise Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input space of the pairwise approach contains pairs of documents, both represented by feature vectors.\n",
    "The output space contains pairwise preference (-1 to +1 values) between each pair of documents.\n",
    "The hypothesis space contains bi-variate functions H that take a pair of documents as the input and output the relative order between them.\n",
    "The loss function measures the inconsistency between two parameter function H and truth label Y. In some algorithms, ranking is modeled as a pairwise classification, and the corresponding classification loss on a pair of documents is used as the loss function. Note that the loss function used in the pairwise approach only considers the relative order between two documents. When one looks at only apair of documents, however, the position of the documents in the final ranked list can hardly be derived. The approach ignores the fact that some pairs are generated from the documents associated with the same query. Considering that most IR evaluation measures are query-level and position-based, intuitively speaking, there is still a gap between this approach and ranking for IR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Listwise approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input space of the listwise approach contains the entire group of documents associated with query.\n",
    "There are two types of output spaces used in the listwise approach. For some listwise ranking algorithms, the output space contains the relevance degrees of all the documents associated with a query. In this case, the ground truth label Y can be derived from the judgment in terms of the relevance degree or total order, in a similar manner to that of the pointwise approach. For some other listwise ranking algorithms, the output space contains the ranked list (or permutation) of the documents. In this case, the ground truth label, denoted as y, can be generated in the following way. \n",
    "The hypothesis space contains multivariate functions H that operate on a group of documents, and predict their relevance degrees or their permutation. For practical reasons, the hypothesis H is also usually implemented with scoring function F. When the relevance degree comprises the output space. When the ranked list (permutation) comprises the output space, H is defined as a compound function. That is, first scoring function F is used to give a score to each document, and then these documents are sorted in the descending order of the scores to produce the desired ranked list. \n",
    "There are also two types of loss functions, corresponding to the two types of output spaces. When the ground truth label is given as y, the loss function is usually defined on the basis of the approximation or bound of widely used IR evaluation measures. When the ground truth label is given as y, the loss function measures the difference between the ranked list given by the hypothesis and the ground truth list. As compared to the pointwise and pairwise approaches, the advantage of the listwise approach lies in that its loss function can naturally consider the positions of documents in the ranked list of all the documents associated with the same query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 MAP metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAP stand for mean average precision. A typical task in information retrieval is for a user to provide a query to a database and retrieving information very similar to the query. For each query, Q, we can calculate a corresponding average precision. A user can have as much queries as he/she likes against this labeled database. The mAP is simply the mean of all the queries that the use made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 NDCG metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDCG stands for Normalized Discounted Cumulative Gain. The main difference between the two is that MAP assumes binary relevance (an item is either of interest or not), while NDCG allows relevance scores in form of real numbers. The relation is just like with classification and regression.\n",
    "Intimidating as the name might be, the idea behind NDCG is pretty simple. A recommender returns some items and we’d like to compute how good the list is. Each item has a relevance score, usually a non-negative number. That’s gain. For items we don’t have user feedback for we usually set the gain to zero.\n",
    "Now scores should be add up; that’s cumulative gain. We’d prefer to see the most relevant items at the top of the list, therefore before summing the scores we divide each by a growing number (usually a logarithm of the item position) - that’s discounting - and get a DCG.\n",
    "DCGs are not directly comparable between users, so we normalize them. The worst possible DCG when using non-negative relevance scores is zero. To get the best, we arrange all the items in the test set in the ideal order, take first K items and compute DCG for them. Then we divide the raw DCG by this ideal DCG to get NDCG@K, a number between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Searching for a solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset is in CSV format and consists of a list identifier, document position on the list, whether the document was appropriate - clicked, 45 numerical features and 5 categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed imports\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import re\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.utils import check_X_y\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('dataset_v2.csv')\n",
    "df = df.drop('doc_rank', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a large data set with near 5 million observations and 53 features. So it seem to be good idea to look for a way to make it more manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.listing_id.compute(), 100, density = 1, facecolor='blue', alpha=0.75)\n",
    "plt.xlabel('Listing Id')\n",
    "plt.title('Histogram of Listing Id')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows that each listing id has a similar number of elements in listing so nothing outlier here. The data is anonymized, so determining the query or content for each item in one list id is not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My target variable is \"clicked\" because the task is to optimize clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked = Counter(df.clicked.values.compute().tolist())\n",
    "plt.bar(clicked.keys(), clicked.values())\n",
    "plt.xticks(list(clicked.keys()))\n",
    "plt.show()\n",
    "\n",
    "df.clicked.compute().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click rate value is extremely low, the non-click impressions are overwhelming, the class are very imbalanced. Features n0 do n44 are numerical values and I will leave it for later. The same as categorical feature c0 to c4. Doc rank column is going to be overwritten so it's redundant here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 30), dpi= 80)\n",
    "sns.heatmap(df.corr(), xticklabels=df.corr().columns, yticklabels=df.corr().columns, cmap='RdYlGn', center=0, annot=True)\n",
    "plt.title('Correlogram of features', fontsize=22)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns n0 to n1 are very correlated with each other. The situation is similar from n3 to n5. Inverse correlation follows between n19 and n20. There is a significant correlation between n21 and n24. The most correlated columns are n25 to n29 - a correlation of 0.98 is practically the same elements. Similar problems continue. Such an extensive training set slows down the learning process which, with so much training data, will be time consuming regardless of the method chosen. If time permits, features selection and optimization will be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "def group_counts(arr):\n",
    "    d = np.ones(arr.size, dtype=int)\n",
    "    d[1:] = (arr[:-1] != arr[1:]).astype(int)\n",
    "    return np.diff(np.where(np.append(d, 1))[0])\n",
    "\n",
    "\n",
    "def group_offsets(arr):\n",
    "    d = np.ones(arr.size, dtype=int)\n",
    "    d[1:] = (arr[:-1] != arr[1:]).astype(int)\n",
    "    idx = np.where(np.append(d, 1))[0]\n",
    "    return zip(idx, idx[1:])\n",
    "\n",
    "\n",
    "def load_docno(fname, letor=False):\n",
    "    if letor:\n",
    "        docno_pattern = re.compile(r'#\\s*docid\\s*=\\s*(\\S+)')\n",
    "    else:\n",
    "        docno_pattern = re.compile(r'#\\s*(\\S+)')\n",
    "\n",
    "    docno = []\n",
    "    for line in open(fname):\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        m = re.search(docno_pattern, line)\n",
    "        if m is not None:\n",
    "            docno.append(m.group(1))\n",
    "    return np.array(docno)\n",
    "\n",
    "\n",
    "def print_trec_run(qid, docno, pred, run_id='exp', output=None):\n",
    "    if output is None:\n",
    "        output = sys.stdout\n",
    "    for a, b in group_offsets(qid):\n",
    "        idx = np.argsort(-pred[a:b]) + a  # note the minus and plus a\n",
    "        for rank, i in enumerate(idx, 1):\n",
    "            output.write('{qid} Q0 {docno} {rank} {sim} {run_id}\\n'.\n",
    "                         format(qid=qid[i], docno=docno[i], rank=rank, sim=pred[i], run_id=run_id))\n",
    "\n",
    "class Scorer(object):\n",
    "    def __init__(self, score_func, **kwargs):\n",
    "        self.score_func = score_func\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.score_func(*args, **self.kwargs)\n",
    "\n",
    "\n",
    "def _burges_dcg(y_true, y_pred, k=None):\n",
    "    # order = np.argsort(y_pred)[::-1]\n",
    "    order = np.argsort(-y_pred)\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gain = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(gain)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def _trec_dcg(y_true, y_pred, k=None):\n",
    "    order = np.argsort(-y_pred)\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gain = y_true\n",
    "    discounts = np.log2(np.arange(len(gain)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def _dcg_score(y_true, y_pred, qid, k=None, dcg_func=None):\n",
    "    assert dcg_func is not None\n",
    "    y_true = np.maximum(y_true, 0)\n",
    "    return np.array([dcg_func(y_true[a:b], y_pred[a:b], k=k) for a, b in group_offsets(qid)])\n",
    "\n",
    "\n",
    "def _ndcg_score(y_true, y_pred, qid, k=None, dcg_func=None):\n",
    "    assert dcg_func is not None\n",
    "    y_true = np.maximum(y_true, 0)\n",
    "    dcg = _dcg_score(y_true, y_pred, qid, k=k, dcg_func=dcg_func)\n",
    "    idcg = np.array([dcg_func(np.sort(y_true[a:b]), np.arange(0, b - a), k=k)\n",
    "                     for a, b in group_offsets(qid)])\n",
    "    assert (dcg <= idcg).all()\n",
    "    idcg[idcg == 0] = 1\n",
    "    return dcg / idcg\n",
    "\n",
    "\n",
    "def dcg_score(y_true, y_pred, qid, k=None, version='burges'):\n",
    "    assert version in ['burges', 'trec']\n",
    "    dcg_func = _burges_dcg if version == 'burges' else _trec_dcg\n",
    "    return _dcg_score(y_true, y_pred, qid, k=k, dcg_func=dcg_func)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_pred, qid, k=None, version='burges'):\n",
    "    assert version in ['burges', 'trec']\n",
    "    dcg_func = _burges_dcg if version == 'burges' else _trec_dcg\n",
    "    return _ndcg_score(y_true, y_pred, qid, k=k, dcg_func=dcg_func)\n",
    "\n",
    "\n",
    "class DCGScorer(Scorer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DCGScorer, self).__init__(dcg_score, **kwargs)\n",
    "\n",
    "\n",
    "class NDCGScorer(Scorer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NDCGScorer, self).__init__(ndcg_score, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pointwise approach algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for some tests. Here would be cover the pointwise approach. According to 3.2 its basic machine learning model, regression in this case. I choose Gradient Boosting Regressor for this one. Each model will be fitted on balanced data - with no disproportion between click and non-click samples - for faster training and scores will be calculated two times, on balance data and whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise():\n",
    "\n",
    "    clicked_values = df.clicked.values\n",
    "    clicked_id = [i for i in range(len(clicked_values)) if clicked_values[i] == 1]\n",
    "    not_clicked_id = [cid - 1 for cid in clicked_id]\n",
    "    new_indexes = clicked_id + not_clicked_id\n",
    "    new_indexes.sort()\n",
    "    x_train = df.drop('clicked', axis=1).values[new_indexes, :]\n",
    "    y_train = df.clicked.values[new_indexes]\n",
    "\n",
    "    scaler = Normalizer()\n",
    "\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    \n",
    "    num_queries = len(df.groupby('listing_id'))\n",
    "    queries = np.array(range(num_queries))\n",
    "    \n",
    "    model = GradientBoostingRegressor()\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Balanced score: \")\n",
    "    predictionsb = model.predict(x_train)\n",
    "\n",
    "    score = NDCGScorer(k=5)(y_train, predictionsb, queries).mean()\n",
    "    print('nDCG@{}\\t{}'.format(5, score)) \n",
    "\n",
    "    x_train = df.drop('clicked', axis=1).values\n",
    "    y_train = df.clicked.values\n",
    "\n",
    "    predictionsa = model.predict(x_train)\n",
    "\n",
    "    print(\"All data score: \")\n",
    "    score = NDCGScorer(k=5)(y_train, predictionsa, queries).mean()\n",
    "    print('nDCG@{}\\t{}'.format(5, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute point wise approach\n",
    "point_wise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Pairwise approach algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test with pair wise approach RankSVM algorithm would be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pairwise(X, y):\n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim == 1:\n",
    "        y = np.c_[y, np.ones(y.shape[0])]\n",
    "    comb = itertools.combinations(range(X.shape[0]), 2)\n",
    "    for k, (i, j) in enumerate(comb):\n",
    "        if y[i, 0] == y[j, 0] or y[i, 1] != y[j, 1]:\n",
    "            # skip if same target or different group\n",
    "            continue\n",
    "        X_new.append(X[i] - X[j])\n",
    "        y_new.append(np.sign(y[i, 0] - y[j, 0]))\n",
    "        # output balanced classes\n",
    "        if y_new[-1] != (-1) ** k:\n",
    "            y_new[-1] = - y_new[-1]\n",
    "            X_new[-1] = - X_new[-1]\n",
    "    return np.asarray(X_new), np.asarray(y_new).ravel()\n",
    "\n",
    "\n",
    "class RankSVM(SGDClassifier):\n",
    "    def fit(self, X, y):\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        super(RankSVM, self).fit(X_trans, y_trans)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = super(RankSVM, self).predict(X)\n",
    "        return pred\n",
    "\n",
    "    def score(self, X, y):\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        return np.mean(super(RankSVM, self).predict(X_trans) == y_trans)\n",
    "\n",
    "def pair_wise():\n",
    "\n",
    "    clicked_values = df.clicked.values\n",
    "    clicked_id = [i for i in range(len(clicked_values)) if clicked_values[i] == 1]\n",
    "    not_clicked_id = [cid - 1 for cid in clicked_id]\n",
    "    new_indexes = clicked_id + not_clicked_id\n",
    "    new_indexes.sort()\n",
    "    x_train = df.drop('clicked', axis=1).values[new_indexes, :]\n",
    "    y_train = df.clicked.values[new_indexes]\n",
    "\n",
    "    scaler = Normalizer()\n",
    "\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    \n",
    "    num_queries = len(df.groupby('listing_id'))\n",
    "    queries = np.array(range(num_queries))\n",
    "    \n",
    "    model = RankSVM(alpha=0.01, loss='hinge')\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Balanced score: \")\n",
    "    predictionsb = model.predict(x_train)\n",
    "\n",
    "    score = NDCGScorer(k=5)(y_train, predictionsb, queries).mean()\n",
    "    print('nDCG@{}\\t{}'.format(5, score)) \n",
    "\n",
    "    x_train = df.drop('clicked', axis=1).values\n",
    "    y_train = df.clicked.values\n",
    "\n",
    "    predictionsa = model.predict(x_train)\n",
    "\n",
    "    print(\"All data score: \")\n",
    "    score = NDCGScorer(k=5)(y_train, predictionsa, queries).mean()\n",
    "    print('nDCG@{}\\t{}'.format(5, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair wise - it would take some time\n",
    "pair_wise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Listwise approach algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And AdaRank will cover the listwise approach test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaRank(sklearn.base.BaseEstimator):\n",
    "    \"\"\"AdaRank algorithm\"\"\"\n",
    "\n",
    "    def __init__(self, max_iter=500, tol=0.0001, estop=1, verbose=False, scorer=None):\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.estop = estop\n",
    "        self.verbose = verbose\n",
    "        self.scorer = scorer\n",
    "\n",
    "    def fit(self, X, y, qid, X_valid=None, y_valid=None, qid_valid=None):\n",
    "        \"\"\"Fit a model to the data\"\"\"\n",
    "        X, y = check_X_y(X, y, 'csr')\n",
    "        #X = X.toarray()\n",
    "\n",
    "        if X_valid is None:\n",
    "            X_valid, y_valid, qid_valid = X, y, qid\n",
    "        else:\n",
    "            X_valid, y_valid = check_X_y(X_valid, y_valid, 'csr')\n",
    "            X_valid = X_valid.toarray()\n",
    "\n",
    "        n_queries = np.unique(qid).shape[0]\n",
    "        weights = np.ones(n_queries, dtype=np.float64) / n_queries\n",
    "        weak_rankers = []\n",
    "        coef = np.zeros(X.shape[1])\n",
    "\n",
    "        if self.scorer is None:\n",
    "            self.scorer = NDCGScorer(k=10)\n",
    "\n",
    "        weak_ranker_score = []\n",
    "        for j in range(X.shape[1]):\n",
    "            pred = X[:, j].ravel()\n",
    "            weak_ranker_score.append(self.scorer(y, pred, qid))\n",
    "\n",
    "        best_perf_train = -np.inf\n",
    "        best_perf_valid = -np.inf\n",
    "        used_fids = []\n",
    "        estop = None\n",
    "\n",
    "        self.n_iter = 0\n",
    "        while self.n_iter < self.max_iter:\n",
    "            self.n_iter += 1\n",
    "\n",
    "            best_weighted_average = -np.inf\n",
    "            best_weak_ranker = None\n",
    "            for fid, score in enumerate(weak_ranker_score):\n",
    "                if fid in used_fids:\n",
    "                    continue\n",
    "                weighted_average = np.dot(weights, score)\n",
    "                if weighted_average > best_weighted_average:\n",
    "                    best_weak_ranker = {'fid': fid, 'score': score}\n",
    "                    best_weighted_average = weighted_average\n",
    "\n",
    "            if best_weak_ranker is None:\n",
    "                break\n",
    "\n",
    "            h = best_weak_ranker\n",
    "            h['alpha'] = 0.5 * (math.log(np.dot(weights, 1 + h['score']) /\n",
    "                                         np.dot(weights, 1 - h['score'])))\n",
    "            weak_rankers.append(h)\n",
    "\n",
    "            coef[h['fid']] += h['alpha']\n",
    "\n",
    "            score_train = self.scorer(y, np.dot(X, coef), qid)\n",
    "            perf_train = score_train.mean()\n",
    "\n",
    "            perf_valid = perf_train\n",
    "            if X_valid is not X:\n",
    "                perf_valid = self.scorer(y_valid, np.dot(X_valid, coef), qid_valid).mean()\n",
    "\n",
    "            if self.verbose:\n",
    "                print('{n_iter}\\t{alpha}\\t{fid}\\t{score}\\ttrain {train:.4f}\\tvalid {valid:.4f}'.\n",
    "                      format(n_iter=self.n_iter, alpha=h['alpha'], fid=h['fid'],\n",
    "                             score=h['score'][:5], train=perf_train, valid=perf_valid),\n",
    "                      file=sys.stderr)\n",
    "\n",
    "            if perf_valid > best_perf_valid + self.tol:\n",
    "                estop = 0\n",
    "                best_perf_valid = perf_valid\n",
    "                self.coef_ = coef.copy()\n",
    "            else:\n",
    "                estop += 1\n",
    "\n",
    "            if perf_train > best_perf_train + self.tol:\n",
    "                best_perf_train = perf_train\n",
    "            else:\n",
    "                if estop >= self.estop:\n",
    "                    break\n",
    "\n",
    "            # update weights\n",
    "            new_weights = np.exp(-score_train)\n",
    "            weights = new_weights / new_weights.sum()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, qid):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        return np.dot(X, self.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_wise():\n",
    "\n",
    "    clicked_values = df.clicked.values\n",
    "    clicked_id = [i for i in range(len(clicked_values)) if clicked_values[i] == 1]\n",
    "    not_clicked_id = [cid - 1 for cid in clicked_id]\n",
    "    new_indexes = clicked_id + not_clicked_id\n",
    "    new_indexes.sort()\n",
    "    x_train = df.drop('clicked', axis=1).values[new_indexes, :]\n",
    "    y_train = df.clicked.values[new_indexes]\n",
    "\n",
    "    scaler = Normalizer()\n",
    "\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    \n",
    "    num_queries = len(df.groupby('listing_id'))\n",
    "    queries = np.array(range(num_queries))\n",
    "    \n",
    "    model = AdaRank(max_iter=100, estop=10, verbose=False, scorer=NDCGScorer(k=num_queries))\n",
    "    model.fit(x_train, y_train, queries)\n",
    "    \n",
    "    print(\"Balanced score: \")\n",
    "    predictionsb = model.predict(x_train, queries)\n",
    "\n",
    "    score = NDCGScorer(k=5)(y_train, predictionsb, queries).mean()\n",
    "    print('nDCG@{}\\t{}'.format(5, score)) \n",
    "\n",
    "    x_train = df.drop('clicked', axis=1).values\n",
    "    y_train = df.clicked.values\n",
    "\n",
    "    predictionsa = model.predict(x_train, queries)\n",
    "\n",
    "    print(\"All data score: \")\n",
    "    score = NDCGScorer(k=5)(y_train, predictionsa, queries).mean()\n",
    "    print('nDCG@{}\\t{}'.format(5, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute list wise approach\n",
    "list_wise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above methods do not give satisfactory results. This is the result of both the algorithms used and the data owned, as well as their processing. Also the problem is number of existing algorithsm for Learning to Rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Proposed solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods used to solve the Learning to Rate problem are constantly optimized - one comes from the other - so their number is constantly growing, and choosing the optimal solution for a given dataset can be time consuming. The proposed solution will be much more flexible because it will combine the issues of neural networks supported by Bayesian search and genetic algorithms. The whole is very complex but therefore also flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea is that you use multiple starting points (as opposed to one) and update each of them in parallel (according to their specific methodology) and hopefully they will all converge to the same global minima. While one or two may have a high risk of getting stuck in a local minima, the probability that multiple get stuck in the same local minima is highly unlikely and thus by following the majority of the agents, you can be more confident that the true global minima has been found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Genetic Algorithms to evolve the best weights and bias values (and even other features like the network architecture and activation functions, etc) is an interesting variant known as NeuroEvolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genetic algorithms as an alternative method for training Neural Networks (of any architecture, often without requiring layers and each neuron need not have the same activation function, etc ). It not the most widely used method because it is more compute intensive than methods like back-propagation, but neuroevolution can be advantageous when the error gradient is extremely uneven (contains a lot of local minima) or the fitness landscape is dynamic (i.e. where the error gradient may change over time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea behind using those algorithms to evolve neural networks is:\n",
    "* start with a random population of neural nets\n",
    "* measure each and decide on their fitness (NDCG metric in our case).\n",
    "* Then kill off the worst variants (those with low fitnesses or NDCG scores) and keep the fittest to proceed to the next generation\n",
    "* The new population will be far fitter but far fewer, so we need a way to introduce more variants to bring up the numbers. Using random ones would not take advantage of what we have learnt so far (i.e. that the fitter individuals possess some features which make them better at the task). So we “breed” the fitter individuals to produce offspring . This involves taking the vector representation (known as a genome) of two fit individuals and somehow combining them together to form a new vector (genome). The process of combining them is known as crossover.\n",
    "* Then I add a slight bit of randomness into the mix (known as mutation) to introduce new variants into the population (in case our fittest genes simply aren’t good enough to begin with)\n",
    "* repeat this whole process for a few hundred generations and finish! The fitness of the evolving population should increase until they converge upon the global minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do this by modifying the method called NEAT(NeuroEvolution of Augmenting Topologies) - EFFICIENT EVOLUTION OF NEURAL NETWORKS THROUGH COMPLEXIFICATION, Kenneth O. Stanley."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each genome contains a list of connected genes, each of which refers to two nodes. Each connected gene determines the input node, output node, connection weight, regardless of whether the linked gene is activated (activation bit) and innovation number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key observation is that two genes with the same origin represent the same structure. Innovation numbers are therefore the chronology of each gene in the system. The numbers of innovations never change. Thus, the origin of each gene in the system is known during evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new structure to the network usually reduces the fit at first. However, NEAT is primarily a population speciation, so that individuals compete primarily in their own niches instead of the entire population. In this way topological innovations are protected and have time to optimize their structure before they have to compete with other niches in the population. As a reproduction mechanism at NEAT, we use explicit match-sharing, where organisms of the same species need to share their niche's fit, making it difficult for one species to take over the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new structure is introduced incrementally when structural mutations appear and only those structures survive that prove important by assessing adaptation. In this way, NEAT searches the minimum number of weight dimensions, significantly reducing the number of generations needed to find a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example contains the base for this solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.layers import Input, Embedding, multiply, Dropout, Dense, Flatten, concatenate\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "\n",
    "def map_data(series: pd.Series) -> dict:\n",
    "    return dict([(y, x + 1) for x, y in enumerate(series.unique())])\n",
    "\n",
    "\n",
    "def build_model(max_queries: int, max_doc: int) -> Model:\n",
    "    dim_embedddings = 30\n",
    "    bias = 1\n",
    "\n",
    "    queries_inputs = Input(shape=(1,))\n",
    "    queries = Embedding(max_queries + 1, dim_embedddings, name=\"queries\")(queries_inputs)\n",
    "    queries_bias = Embedding(max_queries + 1, bias, name=\"queries_bias\")(queries_inputs)\n",
    "\n",
    "    doc_inputs = Input(shape=(1,))\n",
    "    doc = Embedding(max_doc + 1, dim_embedddings, name=\"doc\")(doc_inputs)\n",
    "    doc_bias = Embedding(max_doc + 1, bias, name=\"doc_bias\")(doc_inputs)\n",
    "\n",
    "    clicked_input = Input(shape=(1,))\n",
    "    clicked_layer = Dense(dim_embedddings)(clicked_input)\n",
    "\n",
    "    network = multiply([doc, queries, clicked_layer])\n",
    "    network = Dropout(0.3)(network)\n",
    "    network = concatenate([network, queries_bias, doc_bias])\n",
    "    network = Flatten()(network)\n",
    "    network = Dense(10, activation=\"relu\")(network)\n",
    "    network = Dense(1)(network)\n",
    "\n",
    "    model = Model(inputs=[doc_inputs, queries_inputs, clicked_input], outputs=network)\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = dd.read_csv('dataset_v2.csv')\n",
    "    df['doc_id'] = df.doc_rank\n",
    "    df = df.compute()\n",
    "\n",
    "    mapped_doc_ids = map_data(df.doc_id)\n",
    "    df.doc_id = df.doc_id.map(mapped_doc_ids)\n",
    "\n",
    "    mapped_queries_ids = map_data(df.listing_id)\n",
    "    df.listing_id = df.listing_id.map(mapped_queries_ids)\n",
    "\n",
    "    max_doc_id = max(df.doc_id.tolist())\n",
    "    max_queries_id = max(df.listing_id.tolist())\n",
    "\n",
    "    model = build_model(max_queries_id, max_doc_id)\n",
    "    model.fit([df.doc_id.values, df.listing_id.values, df.clicked.values], df.doc_rank.values, verbose=0)\n",
    "    prediction = model.predict([df.doc_id.values, df.listing_id, df.clicked.values])\n",
    "\n",
    "    num_queries = len(df.groupby('listing_id'))\n",
    "    queries = np.array(range(num_queries))\n",
    "\n",
    "    score = NDCGScorer(k=5)(df.doc_rank.values, prediction, queries).mean()\n",
    "    print('nDCG@{}\\t{}'.format(5, score))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, the network input is simplified to speed up calculations, yet the NDCG result is decent but we aim higher. Particular attention should be paid to neural network architecture. It forms the base of the solution used by NEAT. It will look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_queries: int, max_doc: int, bias: int = 1, dim_embedings: int = 30) -> Model:\n",
    "\n",
    "    queries_inputs = Input(shape=(1,))\n",
    "    queries = Embedding(max_queries + 1, dim_embedddings, name=\"queries\")(queries_inputs)\n",
    "    queries_bias = Embedding(max_queries + 1, bias, name=\"queries_bias\")(queries_inputs)\n",
    "\n",
    "    doc_inputs = Input(shape=(1,))\n",
    "    doc = Embedding(max_doc + 1, dim_embedddings, name=\"doc\")(doc_inputs)\n",
    "    doc_bias = Embedding(max_doc + 1, bias, name=\"doc_bias\")(doc_inputs)\n",
    "\n",
    "    clicked_input = Input(shape=(1,))\n",
    "    clicked_layer = Dense(dim_embedddings)(clicked_input)\n",
    "\n",
    "    network = multiply([doc, queries, clicked_layer])\n",
    "    network = Dropout(0.3)(network)\n",
    "    network = concatenate([network, queries_bias, doc_bias])\n",
    "    network = Flatten()(network)\n",
    "    ''' Here would be all layers and single neurons added by NEAT\n",
    "    For example:\n",
    "    network = Dense(10, activation=\"relu\")(network)\n",
    "    '''\n",
    "    \n",
    "    network = Dense(1)(network)\n",
    "\n",
    "    model = Model(inputs=[doc_inputs, queries_inputs, clicked_input], outputs=network)\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=[\"NDCG\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My solution assumes the above network expanded by NEAT. In each generation, NEAT would perform operations characteristic of genetic algorithms such as mutation and crossing, emerging networks would be searched for hyperparameters (activation functions, learning rate, batch size, optimizer) to optimize network efficiency. The adaptation function will be the NDCG result. Genomes (created networks) with the highest results will go to the next generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution could work endlessly, therefore the key issue is to define stop conditions. There are 3 stop conditions: the first is to achieve the determined efficiency (for example, NDCG = 0.98), the second is the N generation not making progress (for example, for 30 generations - so-called Early Stopping), the third is to reach the designated number of generations. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
